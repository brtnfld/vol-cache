name: linux 

on:
  pull_request:
    branches: [ develop ]

  push:
    branches: [ develop ]
    paths-ignore:
      - '**.md'
      - '**.txt'
      - 'docs/**'
      
  # Allows to run this workflow manually from the Actions tab
  workflow_dispatch:
jobs:
  vol-cache:
    runs-on: ubuntu-latest
    timeout-minutes: 60

    steps:
      - uses: actions/checkout@v2
      - name: Checkout submodule argobots
        run: git submodule update --init --recursive
      
      
      - name: Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install libtool
          # hdf5
          git clone https://github.com/HDFGroup/hdf5.git	  
          # async vol
          git clone https://github.com/hpc-io/vol-async.git
          # Argobots
          git clone https://github.com/pmodels/argobots.git
          # h5bench
          git clone https://github.com/hpc-io/h5bench.git
          cd h5bench
          git pull https://github.com/zhenghh04/h5bench.git
          cd -
          # mpi
          sudo apt-get install libopenmpi-dev
          # zlib
          sudo apt-get install zlib1g-dev 
          # python3
          sudo apt-get install python3
          
      - name: Installation
        run: |
          export mydir="$PWD"
          export EXAHDF5_ROOT=$mydir
          export SDK_DIR=$EXAHDF5_ROOT/soft/
          mkdir $SDK_DIR
          export HDF5_ROOT=$SDK_DIR/hdf5/
          mkdir $HDF5_ROOT
          export HDF5_HOME=$HDF5_ROOT
          export HDF5_DIR=$HDF5_ROOT
          export HDF5_VOL_DIR=$SDK_DIR/hdf5/vol/
          mkdir $HDF5_VOL_DIR
          mkdir $HDF5_VOL_DIR/lib/
          mkdir $HDF5_VOL_DIR/include/
          export ABT_DIR=$SDK_DIR/argobots/
          mkdir $ABT_DIR
          # Compile HDF5
          cd hdf5
          export HDF5_LIBTOOL=/usr/bin/libtoolize
          ./autogen.sh
          ./configure --prefix=$HDF5_DIR --enable-parallel --enable-threadsafe --enable-unsupported
          make && make install
          cd -
          cd argobots
          ./autogen.sh
          ./configure --prefix=$ABT_DIR
          make && make install
          cd -
          # Compile Asynchronous VOL connector
          cd vol-async/src
          tail -n 48 Makefile.summit > Makefile
          make
          cp lib* $HDF5_VOL_DIR/lib
          cp *.h $HDF5_VOL_DIR/include
          cd -
          # Compile Cache VOL connector
          cd ./src
          make all
          cd ../benchmarks
          make all
          cd ../tests
          make all
          cd ../
          # Compile h5bench
          mkdir h5bench/build
          cd h5bench/build
          cmake .. -DCMAKE_C_COMPILER=mpicc -DCMAKE_CXX_COMPILER=mpicxx -DCMAKE_INSTALL_PREFIX=$SDK_DIR/h5bench  -DWITH_CACHE_VOL:BOOL=ON -DWITH_ASYNC_VOL:BOOL=ON -DCMAKE_C_FLAGS="-I/$HDF5_VOL_DIR/include -L/$HDF5_VOL_DIR/lib -g"
          make all install VERBOSE=1
          cd -
      - name: Test Vol-Cache-Node-Local
        run: |
          mydir="$PWD"
          cd $mydir
          # Set Environmental Variables
          export EXAHDF5_ROOT=$PWD
          export SDK_DIR=$EXAHDF5_ROOT/soft/
          export HDF5_ROOT=$SDK_DIR/hdf5
          export HDF5_HOME=$HDF5_ROOT
          export HDF5_DIR=$HDF5_ROOT
          export HDF5_VOL_DIR=$SDK_DIR/hdf5/vol
          export ABT_DIR=$SDK_DIR/argobots/
          export LD_LIBRARY_PATH=$ABT_DIR/lib:$LD_LIBRARY_PATH
          export LD_LIBRARY_PATH=$HDF5_ROOT/lib:$HDF5_VOL_DIR/lib:$LD_LIBRARY_PATH
          export PATH=$EXAHDF5_ROOT/soft/h5bench/bin:$PATH
          export HDF5_PLUGIN_PATH=$HDF5_VOL_DIR/lib
          export HDF5_VOL_CONNECTOR="cache_ext config=cache_1.cfg;under_vol=512;under_info={under_vol=0;under_info={}}"
          export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:$HDF5_PLUGIN_PATH
          export DEBUG=2
          export LD_PRELOAD=$ABT_DIR/lib/libabt.so
          cd tests
          printf "HDF5_CACHE_STORAGE_TYPE: SSD\nHDF5_CACHE_STORAGE_PATH: SSD\nHDF5_CACHE_STORAGE_SCOPE: LOCAL\nHDF5_CACHE_STORAGE_SIZE: 128755813888\nHDF5_CACHE_WRITE_BUFFER_SIZE: 17179869184" > cache_1.cfg
          [ -e SSD ] || mkdir SSD
          for opt in 'yes' 'no'
          do
              echo "Testing"
              HDF5_CACHE_WR=$opt mpirun -np 2 ./test_dataset
              HDF5_CACHE_WR=$opt mpirun -np 2 ./test_dataset_async_api
              HDF5_CACHE_WR=$opt mpirun -np 2 ./test_group
              HDF5_CACHE_WR=$opt mpirun -np 2 ./test_file
              HDF5_CACHE_WR=$opt mpirun -np 2 h5bench_write ./test_h5bench.cfg test.h5
          done
          cd ../benchmarks/
          [ -e SSD ] || mkdir SSD
          printf "HDF5_CACHE_STORAGE_TYPE: SSD\nHDF5_CACHE_STORAGE_PATH: SSD\nHDF5_CACHE_STORAGE_SCOPE: LOCAL\nHDF5_CACHE_STORAGE_SIZE: 128755813888\nHDF5_CACHE_WRITE_BUFFER_SIZE: 17179869184" > cache_1.cfg
          HDF5_CACHE_WR=yes mpirun -np 2 ./test_write_cache
          HDF5_CACHE_WR=no mpirun -np 2 ./test_write_cache

